FANN_FLO_2.1
num_layers=3
learning_rate=0.700000
connection_rate=1.000000
network_type=0
learning_momentum=0.000000
training_algorithm=2
train_error_function=1
train_stop_function=0
cascade_output_change_fraction=0.010000
quickprop_decay=-0.000100
quickprop_mu=1.750000
rprop_increase_factor=1.200000
rprop_decrease_factor=0.500000
rprop_delta_min=0.000000
rprop_delta_max=50.000000
rprop_delta_zero=0.100000
cascade_output_stagnation_epochs=12
cascade_candidate_change_fraction=0.010000
cascade_candidate_stagnation_epochs=12
cascade_max_out_epochs=150
cascade_min_out_epochs=50
cascade_max_cand_epochs=150
cascade_min_cand_epochs=50
cascade_num_candidate_groups=2
bit_fail_limit=3.49999994039535522461e-001
cascade_candidate_limit=1.00000000000000000000e+003
cascade_weight_multiplier=4.00000005960464477539e-001
cascade_activation_functions_count=10
cascade_activation_functions=3 5 7 8 10 11 14 15 16 17 
cascade_activation_steepnesses_count=4
cascade_activation_steepnesses=2.50000000000000000000e-001 5.00000000000000000000e-001 7.50000000000000000000e-001 1.00000000000000000000e+000 
layer_sizes=11 12 2 
scale_included=0
neurons (num_inputs, activation_function, activation_steepness)=(0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (0, 0, 0.00000000000000000000e+000) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (11, 4, 5.00000000000000000000e-001) (0, 0, 0.00000000000000000000e+000) (12, 4, 5.00000000000000000000e-001) (0, 0, 0.00000000000000000000e+000) 
connections (connected_to_neuron, weight)=(0, 2.21446469426155090332e-001) (1, -2.63309812545776367188e+000) (2, 1.31560766696929931641e+000) (3, -3.01668941974639892578e-001) (4, -8.49552631378173828125e-001) (5, -2.80846047401428222656e+000) (6, -7.38366270065307617188e+000) (7, 1.21557207107543945312e+001) (8, 2.84581589698791503906e+000) (9, -2.62487430572509765625e+001) (10, 6.60600125789642333984e-001) (0, 2.14162353515625000000e+002) (1, -3.50468902587890625000e+001) (2, 4.13125114440917968750e+001) (3, -1.42450304031372070312e+001) (4, -6.18780708312988281250e+000) (5, -1.01212333679199218750e+002) (6, 1.87898361206054687500e+002) (7, 1.77450942993164062500e+002) (8, 4.47168846130371093750e+001) (9, -9.38769226074218750000e+002) (10, -2.76878148317337036133e-001) (0, 4.81256055831909179688e+000) (1, 4.79933977127075195312e-001) (2, 3.77533167600631713867e-001) (3, 1.44363832473754882812e+000) (4, -3.51754069328308105469e-001) (5, -1.95784831047058105469e+000) (6, -5.91373586654663085938e+000) (7, 2.57190189361572265625e+001) (8, 8.04166376590728759766e-001) (9, -2.28338127136230468750e+001) (10, 9.94530841708183288574e-002) (0, -5.01495695114135742188e+000) (1, 5.59471178054809570312e+000) (2, 1.11136140823364257812e+001) (3, 5.74254035949707031250e-001) (4, 3.83227735757827758789e-001) (5, -4.69536989927291870117e-001) (6, 2.70893001556396484375e+000) (7, 1.09647598266601562500e+001) (8, 2.26032924652099609375e+000) (9, -3.51127014160156250000e+001) (10, 2.97730267047882080078e-001) (0, 2.55287216186523437500e+002) (1, -1.22593040466308593750e+001) (2, 3.11087188720703125000e+002) (3, 2.07497924566268920898e-001) (4, 1.30509182810783386230e-001) (5, -5.14209461212158203125e+000) (6, -1.50000000000000000000e+003) (7, -1.48118945312500000000e+003) (8, -6.95035034179687500000e+002) (9, 1.94488105773925781250e+001) (10, 5.48999667167663574219e-001) (0, -7.86067199707031250000e+002) (1, -1.46332168579101562500e+002) (2, -2.53258347511291503906e-001) (3, -2.39062237739562988281e+000) (4, -4.81533145904541015625e+000) (5, -1.05648107910156250000e+003) (6, 3.99450805664062500000e+002) (7, 4.31139770507812500000e+002) (8, -9.69847595214843750000e+002) (9, -8.79514831542968750000e+002) (10, -2.54491478204727172852e-001) (0, 1.27419424057006835938e+000) (1, 5.54550695419311523438e+000) (2, 7.72484207153320312500e+000) (3, -9.53601300716400146484e-001) (4, -8.61618161201477050781e-001) (5, -5.47816467285156250000e+001) (6, -2.00181694030761718750e+001) (7, 2.07709922790527343750e+001) (8, 2.41002798080444335938e+000) (9, 1.63658103942871093750e+001) (10, 1.11231289803981781006e-001) (0, -9.50240731239318847656e-001) (1, -8.50195407867431640625e-001) (2, 4.26972061395645141602e-001) (3, 3.11339879035949707031e+000) (4, -9.90917444229125976562e-001) (5, -7.05620956420898437500e+000) (6, -9.45367145538330078125e+000) (7, 5.06844673156738281250e+001) (8, -6.57532453536987304688e-001) (9, -2.51838054656982421875e+001) (10, -4.82448041439056396484e-001) (0, 4.02945518493652343750e+000) (1, -3.60227508544921875000e+002) (2, 1.87197631835937500000e+002) (3, 1.03006504476070404053e-001) (4, -5.04935532808303833008e-002) (5, -1.49443481445312500000e+003) (6, -1.50000000000000000000e+003) (7, -1.50000000000000000000e+003) (8, -1.46932324218750000000e+003) (9, -1.35145227050781250000e+003) (10, 3.14986658096313476562e+000) (0, 2.67473316192626953125e+000) (1, 5.21157932281494140625e+000) (2, 2.47330141067504882812e+000) (3, 1.08820590972900390625e+001) (4, 6.46823942661285400391e-001) (5, -1.21944949030876159668e-001) (6, -2.13815097808837890625e+001) (7, 1.18767719268798828125e+001) (8, 4.15901718139648437500e+001) (9, -5.45369195938110351562e+000) (10, 3.86140525341033935547e-001) (0, 7.35449752807617187500e+001) (1, -1.46473266601562500000e+003) (2, 4.50692939758300781250e+000) (3, 2.06071689724922180176e-001) (4, 3.19332569837570190430e-001) (5, -1.49894641113281250000e+003) (6, -1.29338000488281250000e+003) (7, -1.49878674316406250000e+003) (8, -1.46930944824218750000e+003) (9, -1.42833862304687500000e+003) (10, 8.37412416934967041016e-001) (11, -1.07606148719787597656e+000) (12, 1.94966316223144531250e-001) (13, -6.20627701282501220703e-001) (14, 1.19651407003402709961e-001) (15, -3.68051081895828247070e-001) (16, 6.34280070662498474121e-002) (17, -9.42176878452301025391e-001) (18, -7.46721148490905761719e-001) (19, -3.29265385866165161133e-001) (20, -5.76162457466125488281e-001) (21, 2.60778991699218750000e+002) (22, 6.18087351322174072266e-001) 
